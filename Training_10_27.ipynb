{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8272a45",
   "metadata": {},
   "source": [
    "# Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2b86b",
   "metadata": {},
   "source": [
    "##### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66de626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import GPUtil\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "#import torchvision\n",
    "#import torchvision.models\n",
    "#import torchvision.transforms as transforms\n",
    "\n",
    "from typing import List\n",
    "\n",
    "## Set up logger to get details of errors\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1a9ea",
   "metadata": {},
   "source": [
    "##### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b55ca182",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df_binary = pd.read_csv(\"https://raw.githubusercontent.com/jcox22/Sagemaker_practice_gan/main/rank_1_curves.csv\")\n",
    "coef_df_binary = coef_df_binary.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2d31750-8b81-4536-b7f3-d7d5908d2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variance variables from data\n",
    "\n",
    "variances = coef_df_binary.describe().loc[['std']]**2\n",
    "\n",
    "real_var = torch.tensor(variances.to_numpy(), dtype = torch.float32, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9993b9c",
   "metadata": {},
   "source": [
    "##### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bffa594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is for number of nodes in each hidden layer of NN\n",
    "k = 10000\n",
    "\n",
    "# For number of inputs (32 binary digits)\n",
    "input_length = 32\n",
    "output_length = input_length\n",
    "\n",
    "# Model Parameters\n",
    "epochs = 1000\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "\n",
    "# Needed later on for save_model\n",
    "model_dir = '/models'\n",
    "data_dir = '/training'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7fb104",
   "metadata": {},
   "source": [
    "##### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a5f0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_tensor = torch.tensor(coef_df_binary.to_numpy(), dtype = torch.float32, device = device)\n",
    "train_ds = torch.utils.data.TensorDataset(train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6604e3-7dbd-4c65-9d0a-609afff3e9cd",
   "metadata": {},
   "source": [
    "##### Set Distribution of initial inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8bd77c5e-c75b-44fa-8c9e-d64379cf7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a9093c",
   "metadata": {},
   "source": [
    "##### Create NN Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "711594c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, output_length: int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_layer = nn.Linear(output_length, k)\n",
    "        self.dense_layer2 = nn.Linear(k, k)\n",
    "        self.dense_layer3 = nn.Linear(k, k)\n",
    "        self.dense_layer4 = nn.Linear(k, output_length)\n",
    "\n",
    "    def forward(self, x):\n",
    "        l1 = self.dense_layer(x)\n",
    "        l2 = self.dense_layer2(F.relu(l1))\n",
    "        l3 = self.dense_layer3(F.relu(l2))\n",
    "        l4 = self.dense_layer4(F.relu(l3))\n",
    "        return l4\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense_layer = nn.Linear(int(input_length), k)\n",
    "        self.dense_layer2 = nn.Linear(k, k)\n",
    "        self.dense_layer3 = nn.Linear(k, k)\n",
    "        self.dense_layer4 = nn.Linear(k, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        l1 = self.dense_layer(x)\n",
    "        l2 = self.dense_layer2(F.relu(l1))\n",
    "        l3 = self.dense_layer3(F.relu(l2))\n",
    "        l4 = self.dense_layer4(F.relu(l3))\n",
    "        return l4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e72c88",
   "metadata": {},
   "source": [
    "##### Set up for training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "abdfc5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3893729/3949670600.py:3: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  nn.init.normal(m.weight)\n"
     ]
    }
   ],
   "source": [
    "# Store on GPU else cpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "logger.info(\"Device Type: {}\".format(device))\n",
    "\n",
    "# Call generator and discriminator\n",
    "generator = Generator(output_length)\n",
    "discriminator = Discriminator(input_length)\n",
    "\n",
    "# Make sure it is on device\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "# Apply distrubution type\n",
    "generator.apply(init_normal)\n",
    "discriminator.apply(init_normal)\n",
    "\n",
    "# Loss\n",
    "loss = nn.BCEWithLogitsLoss().to(device)\n",
    "MSE = torch.nn.MSELoss(reduction = 'sum').to(device)\n",
    "\n",
    "# Choose optimizer\n",
    "gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=momentum)\n",
    "\n",
    "dis_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a8e06",
   "metadata": {},
   "source": [
    "##### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44309d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/jcox22/anaconda3/envs/pytorch110/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([1, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 average generator loss 2640287454927767.0\n",
      "epoch:0 average discriminator loss 140.53275008053956\n",
      "epoch:0 average true discriminator loss 9.573726243718792\n",
      "epoch:0 average generator discriminator loss 280.10813805643664\n",
      "Finished Epoch\n",
      "epoch:1 average generator loss 245166732454396.25\n",
      "epoch:1 average discriminator loss 5.026207713154748\n",
      "epoch:1 average true discriminator loss 0.1306223243778101\n",
      "epoch:1 average generator discriminator loss 10.039353193700098\n",
      "Finished Epoch\n",
      "epoch:2 average generator loss 104673092992938.7\n",
      "epoch:2 average discriminator loss 0.00020101520152487301\n",
      "epoch:2 average true discriminator loss 0.004020303900440295\n",
      "epoch:2 average generator discriminator loss 0.0\n",
      "Finished Epoch\n",
      "epoch:3 average generator loss 57976259667725.414\n",
      "epoch:3 average discriminator loss 2.293431045493983\n",
      "epoch:3 average true discriminator loss 0.14363663058230283\n",
      "epoch:3 average generator discriminator loss 4.5724984277589416\n",
      "Finished Epoch\n",
      "epoch:4 average generator loss 36378149076794.52\n",
      "epoch:4 average discriminator loss 4.757041177860589\n",
      "epoch:4 average true discriminator loss 0.2350006933273821\n",
      "epoch:4 average generator discriminator loss 9.490582278728432\n",
      "Finished Epoch\n",
      "epoch:5 average generator loss 24818580315684.59\n",
      "epoch:5 average discriminator loss 0.00624034929558933\n",
      "epoch:5 average true discriminator loss 0.12480698360547213\n",
      "epoch:5 average generator discriminator loss 0.0\n",
      "Finished Epoch\n",
      "epoch:6 average generator loss 17734463348070.64\n",
      "epoch:6 average discriminator loss 0.00010730377579236023\n",
      "epoch:6 average true discriminator loss 0.0021460753906794063\n",
      "epoch:6 average generator discriminator loss 0.0\n",
      "Finished Epoch\n",
      "epoch:7 average generator loss 13058548694684.473\n",
      "epoch:7 average discriminator loss 7.475802981884635\n",
      "epoch:7 average true discriminator loss 0.32544932653010056\n",
      "epoch:7 average generator discriminator loss 14.919061030296401\n",
      "Finished Epoch\n",
      "epoch:8 average generator loss 9968233707253.488\n",
      "epoch:8 average discriminator loss 0.00040708257843521587\n",
      "epoch:8 average true discriminator loss 0.008141651334014696\n",
      "epoch:8 average generator discriminator loss 0.0\n",
      "Finished Epoch\n",
      "epoch:9 average generator loss 7801772858644.927\n",
      "epoch:9 average discriminator loss 0.00013097261660184823\n",
      "epoch:9 average true discriminator loss 0.002619452186007866\n",
      "epoch:9 average generator discriminator loss 0.0\n",
      "Finished Epoch\n",
      "CPU times: user 27.7 s, sys: 10.6 s, total: 38.3 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(0, epochs):\n",
    "    running_loss = 0.0\n",
    "    average_td_gd_loss = 0.0\n",
    "    running_loss_true_d = 0.0\n",
    "    g_d_running_loss = 0.0\n",
    "    for batch in enumerate(train_loader):\n",
    "        noise = torch.randint(0, 2, size=(batch_size, output_length)).float()\n",
    "        noise = noise.to(device)\n",
    "    \n",
    "        # Generate examples of data\n",
    "        true_labels = [1] * batch_size\n",
    "        true_labels = torch.tensor(true_labels).float()\n",
    "        true_labels = true_labels.to(device).resize_((batch_size, 1))\n",
    "            \n",
    "        true_data = batch[1][0]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        gen_optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        #outputs = model(inputs)\n",
    "        #G_of_noise = generator(noise)\n",
    "        #loss = criterion(outputs, labels)\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        G_of_noise = generator(noise)\n",
    "        D_of_G_of_noise = discriminator(G_of_noise)\n",
    "        generator_loss = loss(D_of_G_of_noise, true_labels) + MSE(real_var, torch.var(G_of_noise, dim = 0))\n",
    "        generator_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "            \n",
    "        # Train the discriminator on the true/generated data\n",
    "        dis_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
    "\n",
    "        # add .detach() here think about this\n",
    "        generator_discriminator_out = discriminator(G_of_noise.detach()) # introduce new d_of_g_of_noise without gradient\n",
    "        generator_discriminator_loss = loss(generator_discriminator_out, torch.zeros(batch_size).to(device).resize_((batch_size, 1)))\n",
    "        discriminator_loss = (true_discriminator_loss*0.1 + generator_discriminator_loss) / 2\n",
    "        discriminator_loss.backward()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += generator_loss.item() * len(batch)\n",
    "        average_td_gd_loss += discriminator_loss.item() * len(batch)\n",
    "        running_loss_true_d += true_discriminator_loss.item() * len(batch)\n",
    "        g_d_running_loss += generator_discriminator_loss.item() * len(batch)\n",
    "        #if batch % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            #print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            #print(f\"Loss is {generator_loss.item()}.  Running loss is {running_loss/2000}.  Discriminator loss is {discriminator_loss.item()}.  True Discriminator Loss is {true_discriminator_loss.item()}\")\n",
    "            #print(GPUtil.showUtilization())\n",
    "            #running_loss = 0.0\n",
    "            #print(torch.cuda.memory_summary(device))\n",
    "            #print(torch.cuda.list_gpu_processes(device))\n",
    "        # print(running_loss/10)\n",
    "    print(f\"epoch:{epoch} average generator loss {running_loss / len(train_loader.dataset)}\")\n",
    "    print(f\"epoch:{epoch} average discriminator loss {average_td_gd_loss / len(train_loader.dataset)}\")\n",
    "    print(f\"epoch:{epoch} average true discriminator loss {running_loss_true_d / len(train_loader.dataset)}\")\n",
    "    print(f\"epoch:{epoch} average generator discriminator loss {g_d_running_loss / len(train_loader.dataset)}\")\n",
    "\n",
    "    print(\"Finished Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78567d2",
   "metadata": {},
   "source": [
    "##### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32f13c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        'generator_state_dict': generator.state_dict(),\n",
    "        'optimizer_state_dict': gen_optimizer.state_dict()\n",
    "    }, './gen9.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
