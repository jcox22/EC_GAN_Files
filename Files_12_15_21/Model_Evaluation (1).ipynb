{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f9dc56b-c897-4902-bd47-267d92084a20",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a338b-79c6-4836-bb5f-7fb772c9f7d6",
   "metadata": {},
   "source": [
    "### Setting up Necessary Information to Import the Trained Model\n",
    "\n",
    "Before importing the trained model, we will need to make sure this notebook is ready to run the model.  Running the following cells will do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "4f7d78b3-ada4-40ce-94aa-ea4023cc25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "\n",
    "from typing import List\n",
    "import numpy as np \n",
    "\n",
    "## Set up logger to get details of errors\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b54b3-5c45-4105-a900-7c9537558317",
   "metadata": {},
   "source": [
    "Make sure to make the following parameters match those from when the specified model was trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "7010219d-1398-4293-bb5b-d0806dca97d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is for number of nodes in each hidden layer of NN\n",
    "k = 5000\n",
    "\n",
    "# For number of inputs (32 binary digits)\n",
    "input_length = 32\n",
    "output_length = input_length\n",
    "\n",
    "# Model Parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "var_weight = 0.0\n",
    "layers = 4\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = 'noisy' + str(layers) + 'layers_' + str(epochs) + 'epochs_' + str(k) + 'nodes_' + str(batch_size) + 'batch_size_' + str(lr) + 'lr_' + str(var_weight) + 'var_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "5e0e3890-4d3f-4ea5-8428-6a774c590615",
   "metadata": {},
   "outputs": [],
   "source": [
    "if layers == 3:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, output_length: int):\n",
    "            super(Generator, self).__init__()\n",
    "            self.dense_layer = nn.Linear(output_length, k)\n",
    "            self.dense_layer2 = nn.Linear(k, k)\n",
    "            self.dense_layer3 = nn.Linear(k, output_length)\n",
    "\n",
    "        def forward(self, x):\n",
    "            l1 = self.dense_layer(x)\n",
    "            l2 = self.dense_layer2(F.relu(l1))\n",
    "            l3 = self.dense_layer3(F.relu(l2))\n",
    "            return F.sigmoid(l3)\n",
    "elif layers == 4:\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, output_length: int):\n",
    "            super(Generator, self).__init__()\n",
    "            self.dense_layer = nn.Linear(output_length, k)\n",
    "            self.dense_layer2 = nn.Linear(k, k)\n",
    "            self.dense_layer3 = nn.Linear(k, k)\n",
    "            self.dense_layer4 = nn.Linear(k, output_length)\n",
    "\n",
    "        def forward(self, x):\n",
    "            l1 = self.dense_layer(x)\n",
    "            l2 = self.dense_layer2(F.relu(l1))\n",
    "            l3 = self.dense_layer3(F.relu(l2))\n",
    "            l4 = self.dense_layer4(F.relu(l3))\n",
    "            return F.sigmoid(l4)\n",
    "elif layers == 5:\n",
    "        class Generator(nn.Module):\n",
    "            def __init__(self, output_length: int):\n",
    "                super(Generator, self).__init__()\n",
    "                self.dense_layer = nn.Linear(output_length, k)\n",
    "                self.dense_layer2 = nn.Linear(k, k)\n",
    "                self.dense_layer3 = nn.Linear(k, k)\n",
    "                self.dense_layer4 = nn.Linear(k, k)\n",
    "                self.dense_layer5 = nn.Linear(k, output_length)\n",
    "\n",
    "            def forward(self, x):\n",
    "                l1 = self.dense_layer(x)\n",
    "                l2 = self.dense_layer2(F.relu(l1))\n",
    "                l3 = self.dense_layer3(F.relu(l2))\n",
    "                l4 = self.dense_layer4(F.relu(l3))\n",
    "                l5 = self.dense_layer5(F.relu(l4))\n",
    "                return F.sigmoid(l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "2609ab91-494d-48de-813f-c2bcd73e44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(output_length)\n",
    "generator = generator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868ba58-6556-49d1-ba73-e6647ede618e",
   "metadata": {},
   "source": [
    "### Load in Trained Model\n",
    "\n",
    "In this step we have to specify the correct model for the 'model_name' variable below.  A list of available models should be available in the 'Trained_Models' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "7b2a1bb0-857d-4782-ac19-d015efca7dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure to select the correct model\n",
    "## Model Name defined above with parameters\n",
    "#model_name = '4layers_100epochs_1000nodes_256batch_size_0.001lr_0.1var_weight'\n",
    "model_path = './Trained_Models/generator_' + model_name + '.pt'\n",
    "#model_path = './Trained_Models/generator.pt'\n",
    "curves_path = './Generated_Curves/' + model_name\n",
    "\n",
    "# Load in model\n",
    "generator.load_state_dict(torch.load(model_path)[\"generator_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce7ee4-384e-4bd4-83cb-927140ea75da",
   "metadata": {},
   "source": [
    "### Create Noise\n",
    "\n",
    "This will be the input for the trained generator model.  Having a noisy input will insure that the model has opportunities to generate a variety of different curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "a40137ef-73ed-4766-96f8-036d3c2ffc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randint(0, 2, size=(batch_size, output_length)).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959731a-1643-4abd-844d-428cbfb7e558",
   "metadata": {},
   "source": [
    "### Define function that converts to decimal\n",
    "\n",
    "The raw output of the generator is list of binary-represented numbers.  This function is able to take in that list and convert the numbers from binary to decimal representation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "386b6a29-7fd9-41cc-a79b-ee16fde12411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in decimal numbers between 0 and 1\n",
    "def extract(G_of_noise):\n",
    "\n",
    "    G_numpy = G_of_noise.detach()   \n",
    "\n",
    "    curves = []\n",
    "\n",
    "    for i in range(len(G_numpy)):\n",
    "        c1 = int(G_numpy[i][0].round())\n",
    "        c2 = ((-1)**(int(G_numpy[i][1].round())))*(int(G_numpy[i][2].round()))\n",
    "        c3 = int(G_numpy[i][3].round())\n",
    "        c4 = (-1)**(int(G_numpy[i][4].round()))*(int(\"\".join([str(int(y)) for y in G_numpy[i][5:18].round()]), 2))\n",
    "        c6 = (-1)**(int(G_numpy[i][12].round()))*(int(\"\".join([str(int(y)) for y in G_numpy[i][19:].round()]), 2))\n",
    "    \n",
    "        coef = [c1,c2,c3,c4,c6]\n",
    "        curves.append(coef)\n",
    "    return curves\n",
    "\n",
    "# This function takes in binary digits (0 or 1)\n",
    "def extract_whole_numbers(G_of_noise):\n",
    "\n",
    "    G_numpy = G_of_noise  \n",
    "\n",
    "    curves = []\n",
    "\n",
    "    for i in range(len(G_numpy)):\n",
    "        c1 = int(G_numpy[i][0])\n",
    "        c2 = ((-1)**(int(G_numpy[i][1])))*(int(G_numpy[i][2]))\n",
    "        c3 = int(G_numpy[i][3])\n",
    "        c4 = (-1)**(int(G_numpy[i][4]))*(int(\"\".join([str(int(y)) for y in G_numpy[i][5:18]]), 2))\n",
    "        c6 = (-1)**(int(G_numpy[i][12]))*(int(\"\".join([str(int(y)) for y in G_numpy[i][19:]]), 2))\n",
    "    \n",
    "        coef = [c1,c2,c3,c4,c6]\n",
    "        curves.append(coef)\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b749d7-3c46-4aad-afea-6e3d1892594d",
   "metadata": {},
   "source": [
    "### Generate Results\n",
    "\n",
    "Now we can input the noisy data into the generator to get a sample of curves.  This is saved under the variable 'listcurves'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "ada61749-5c3a-4b3b-9ca8-761b5caddb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/jcox22/anaconda3/envs/pytorch110/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "listcurves = extract(generator(noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94e7f7-ac3a-4315-938e-a77b9aafc58c",
   "metadata": {},
   "source": [
    "We are mainly interested in unique curves that the generator produces, thus we can filter this list to just contain unique curves.  This is saved under the variable 'unique_curves'.  It is also interesting to know how many of the curves are unique and similarly what percent of the curves are unique.  In this cell we also print out these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "e5db048c-e780-43a6-8e77-ddccf930fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique curves generated: 256\n",
      "Percent of generated curves that are unique: 100.0%\n"
     ]
    }
   ],
   "source": [
    "listcurves.sort()\n",
    "unique_curves = list(listcurves for listcurves,_ in itertools.groupby(listcurves))\n",
    "print(\"Number of unique curves generated: {}\".format(len(unique_curves)))\n",
    "print(\"Percent of generated curves that are unique: {}\".format(str(round(len(unique_curves)/batch_size * 100, 2)) + '%'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ea5ecb-abce-4270-bd42-c5c3c4366a7b",
   "metadata": {},
   "source": [
    "In a later code cell we will have to call back to these curves as a list inside a txt file.  Therefore, it is important to save these curves.  Saving the curves as a txt file also allows us to revisit the results of this model down the line if we choose to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "ade6c5b5-b3ba-4846-bd24-ef43cbba68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file that holds the list of unique curves\n",
    "with open(curves_path + '.txt', \"w\") as output:\n",
    "    output.write(str(unique_curves))\n",
    "    \n",
    "# Create a list file that is magma compatable\n",
    "listcurves_magma = \"listcurves := \" + str(unique_curves) + \";\"\n",
    "with open(curves_path + '_magma.txt', \"w\") as output:\n",
    "    output.write(str(listcurves_magma))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339236df-c2cf-454f-9079-f7ffe1a6089a",
   "metadata": {},
   "source": [
    "### Are the curves in the original dataset?\n",
    "\n",
    "Another interesting statistic is whether these curves appear in the original curves dataset that we trained the model on.  \n",
    "\n",
    "In the following cell we import that very dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "e9ef654e-9172-495c-883a-fe1170a73969",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df_binary = pd.read_csv(\"https://raw.githubusercontent.com/jcox22/Sagemaker_practice_gan/main/rank_1_curves.csv\")\n",
    "coef_df_binary = coef_df_binary.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce54e1-c2fd-41fa-bab8-7ac2a3fb5e60",
   "metadata": {},
   "source": [
    "Now we can cross check our generated curves to see if they appear in that dataset.  The output of this cell will tell us that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "ad73c39f-2dbb-465a-8c52-0fab37980176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repeated curves from original dataset: 0\n",
      "Number of unique curves in the generated dataset: 256\n",
      "Percent of generated curves that are new: 100.0\n"
     ]
    }
   ],
   "source": [
    "all_curves = extract_whole_numbers(coef_df_binary.to_numpy().tolist())\n",
    "\n",
    "repeated_curves = 0\n",
    "new_curves = 0\n",
    "total_curves = len(unique_curves)\n",
    "\n",
    "\n",
    "for curve in unique_curves:\n",
    "    if curve in all_curves:\n",
    "        repeated_curves += 1\n",
    "    else:\n",
    "        new_curves +=1\n",
    "print(\"Number of repeated curves from original dataset: {}\".format(repeated_curves))\n",
    "print(\"Number of unique curves in the generated dataset: {}\".format(new_curves))\n",
    "print(\"Percent of generated curves that are new: {}\".format((new_curves/total_curves)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa2631-7bea-408a-bd20-3c7014fb156a",
   "metadata": {},
   "source": [
    "### Check Rank of Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bbd0b-73fa-4b62-b8d3-43d020d85918",
   "metadata": {},
   "source": [
    "Finally, we can take a look at the most important feature of our model: the rank of the curves it generates. The following code uses Magma Calculator to calculate the rank of the elliptic curves.  This step may take some time.\n",
    "\n",
    "# MAKE SURE YOU CHANGE CURVES PATH IN BELOW CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "ab5343c4-0762-4b59-9940-a5f3b06148b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%%bash\n",
    "\n",
    "magma -b -s ./Generated_Curves/noisy4layers_50epochs_5000nodes_256batch_size_0.001lr_0.0var_weight_magma.txt\n",
    "\n",
    "for curve in listcurves do\n",
    "\n",
    "    P<t> := PolynomialRing(Rationals());\n",
    "\n",
    "    e := EllipticCurve(curve);\n",
    "    r := RankBounds(e);\n",
    "    r;\n",
    "\n",
    "end for;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0633428d-7fc9-4cd5-a4ef-95b421071365",
   "metadata": {},
   "source": [
    "Once the calculater is finished, we can take a look at the results.  The following code does a few things.\n",
    "First, it takes in the output of the calculator and filters it to just the intergers (the ranks of the curves).  This is saved as a list called 'ranks'. \n",
    "Second, it saves this ranks list as a text file under the 'Generated_Curves' folder. \n",
    "Third, it prints out the percentage of curves that were generated that fall into three buckets: rank 0, rank 1, and greater than rank 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "6151b638-9af5-4005-b0c7-dceb5c4abc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of generated curves that are rank 0: 27.73%\n",
      "Percent of generated curves that are rank 1: 47.27%\n",
      "Percent of generated curves that are greater than rank 1: 25.0%\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "\n",
    "ranks = []\n",
    "for c in output:\n",
    "    try:\n",
    "        ranks.append(int(c))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "## Save Ranks\n",
    "with open(curves_path + '_ranks.txt', \"w\") as output:\n",
    "    output.write(str(ranks))    \n",
    "    \n",
    "print(\"Percent of generated curves that are rank 0: {}\".format(str(round(ranks.count(0)/len(ranks)*100, 2)) + '%'))\n",
    "print(\"Percent of generated curves that are rank 1: {}\".format(str(round(ranks.count(1)/len(ranks)*100, 2)) + '%'))\n",
    "print(\"Percent of generated curves that are greater than rank 1: {}\".format(str(round((len(ranks) - (ranks.count(0) + ranks.count(1)))/len(ranks)*100, 2)) + '%'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063acc0-a1d2-4155-b2ba-ed75d23226b4",
   "metadata": {},
   "source": [
    "##### Now we know the results of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b42c0f-5818-40c5-bdbd-d6e953f61a9e",
   "metadata": {},
   "source": [
    "###  Checking Archived Results\n",
    "\n",
    "Run the following code to get results from past models.  Make sure to change the name of the file to the name you wish to see the results of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "c53065bd-af33-4f49-b3fd-2c61777aabbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of generated curves that are rank 0: 29.67%\n",
      "Percent of generated curves that are rank 1: 48.35%\n",
      "Percent of generated curves that are greater than rank 1: 21.98%\n"
     ]
    }
   ],
   "source": [
    "## Change the file name below to the desired file\n",
    "\n",
    "with open('./Generated_Curves/noisy4layers_100epochs_1000nodes_256batch_size_0.001lr_1.0var_weight_ranks.txt') as f:\n",
    "    curves_string = f.read()   \n",
    "    \n",
    "curve_ranks = curves_string.strip('][').split(', ')\n",
    "\n",
    "print(\"Percent of generated curves that are rank 0: {}\".format(str(round(curve_ranks.count('0')/len(curve_ranks)*100, 2)) + '%'))\n",
    "print(\"Percent of generated curves that are rank 1: {}\".format(str(round(curve_ranks.count('1')/len(curve_ranks)*100, 2)) + '%'))\n",
    "print(\"Percent of generated curves that are greater than rank 1: {}\".format(str(round((len(curve_ranks) - (curve_ranks.count('0') + curve_ranks.count('1')))/len(curve_ranks)*100, 2)) + '%'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb2825-604d-41ec-b08a-91a38334c9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
